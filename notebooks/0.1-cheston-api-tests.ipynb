{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Building a Representative Corpus of Jazz Piano Trio Recordings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import dependencies, set constants etc."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dotenv\n",
    "import requests\n",
    "import hashlib\n",
    "import string\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "from thefuzz import process\n",
    "from tqdm.notebook import tqdm\n",
    "from requests.exceptions import ConnectionError\n",
    "\n",
    "import src.utils.analyse_utils as autils"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T16:35:08.828780800Z",
     "start_time": "2023-06-05T16:35:08.812250Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# These options just make the outputs from each cell look cleaner\n",
    "pd.set_option('display.max_rows', None)\n",
    "logging.getLogger().setLevel(logging.ERROR)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T15:13:43.172805800Z",
     "start_time": "2023-06-05T15:13:43.167249Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# These variables are constants and can be changed if needed\n",
    "N_PAGES = 500    # The number of LastFM pages to scrape artist information from\n",
    "N_ARTISTS = 500    # The number of artists per LastFM page\n",
    "ROOT = r\"https://ws.audioscrobbler.com/2.0\"    # This is the API root directory that we will make our calls to\n",
    "GENRE = 'jazz'    # The LastFM genre to scrape for artist names\n",
    "SEARCH_TAG = 'trio'    # Only consider artists that have this tag in their name\n",
    "NAME_SIMILARITY_THRESH = 2/3    # Consider track names below this threshold to be unique"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T15:13:43.179750800Z",
     "start_time": "2023-06-05T15:13:43.175807900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get API information\n",
    "\n",
    "To access the LastFM API, we need an API key and shared secret. These must be applied for manually, the procedure for which is out of scope for this notebook. Follow the advice [given in the LastFM API documentation](https://www.last.fm/api/authentication).\n",
    "\n",
    "Once you have an API and shared secret key, these should be stored as environment variables within a file called `.env` that is saved in the root directory of this project folder. These will then be loaded in automatically using the `dotenv` package within the following few lines."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Load in the environment variables we require for authentication\n",
    "dotenv.load_dotenv(rf\"{autils.get_project_root()}\\.env\")\n",
    "LASTFM_API_KEY = os.getenv('LASTFM_API_KEY')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T15:13:43.215748Z",
     "start_time": "2023-06-05T15:13:43.184761300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# These authentication variables aren't currently used, but are created now in case we do end up using them later\n",
    "SHARED_SECRET = os.getenv('LASTFM_SHARED_SECRET')\n",
    "TOKEN = eval(requests.get(f\"{ROOT}/?method=auth.gettoken&api_key={LASTFM_API_KEY}&format=json\").text)['token']\n",
    "API_SIGNATURE = hashlib.md5(f\"api_key{LASTFM_API_KEY}methodauth.getSessiontoken{TOKEN}{SHARED_SECRET}\".encode('utf-8'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T15:13:43.357370900Z",
     "start_time": "2023-06-05T15:13:43.195749300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scrape data from LastFM using API\n",
    "\n",
    "The following cells scrape data from the LastFM API using the information and keys created in the cells above."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def get_total_streams(mbid: str) -> dict:\n",
    "    \"\"\"Gets the total number of streams for an artist by their ID, across all tracks and albums\"\"\"\n",
    "    # Make the API request\n",
    "    request = requests.get(f\"{ROOT}/?method=artist.getinfo&mbid={mbid}&api_key={LASTFM_API_KEY}&format=json\").json()\n",
    "    # Get the required variable from the request JSON object\n",
    "    return {'playcount': request['artist']['stats']['playcount']}\n",
    "\n",
    "def get_top_n_track_streams(mbid: str, num_tracks: int = 3) -> dict:\n",
    "    \"\"\"Gets the number of streams for the top n tracks by an artist, by their ID\"\"\"\n",
    "    # Make the API request\n",
    "    request = requests.get(f\"{ROOT}/?method=artist.gettoptracks&mbid={mbid}&api_key={LASTFM_API_KEY}&format=json\").json()\n",
    "    res_ = {}\n",
    "    # Iterate through the required number of tracks\n",
    "    for tr in range(num_tracks):\n",
    "        # Get the name and play count from the given track\n",
    "        res_[f'track_{tr+1}_name'] = request['toptracks']['track'][tr]['name']\n",
    "        res_[f'track_{tr+1}_plays'] = request['toptracks']['track'][tr]['playcount']\n",
    "    return res_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-06-05T15:13:43.364876900Z",
     "start_time": "2023-06-05T15:13:43.358371100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def process_artist(artist: dict) -> dict:\n",
    "    \"\"\"Central function for processing data from a single artist scraped from LastFM\"\"\"\n",
    "    if SEARCH_TAG.upper() in str(artist['name']).upper():\n",
    "        # We make everything upper case to address any case-sensitivity issues\n",
    "        return {\n",
    "            **artist,\n",
    "            **get_total_streams(mbid=artist['mbid']),\n",
    "            **get_top_n_track_streams(mbid=artist['mbid']),\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T15:13:43.371370600Z",
     "start_time": "2023-06-05T15:13:43.367871100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Empty list to hold our processed data\n",
    "trios = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T15:13:43.378372300Z",
     "start_time": "2023-06-05T15:13:43.375371500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/499 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "84e34908b7bc481f9f45943f02fd9bec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each page of artists on LastFM\n",
    "for i in tqdm(range(1, N_PAGES)):\n",
    "    # Make the API request\n",
    "    try:\n",
    "        tag = requests.get(\n",
    "            f\"{ROOT}/?method=tag.gettopartists&tag={GENRE}&api_key={LASTFM_API_KEY}&page={i}&perpage={N_ARTISTS}&format=json\"\n",
    "        )\n",
    "    # If we time out, log and then continue to the next page\n",
    "    except ConnectionError as e:\n",
    "        print(e)\n",
    "        pass\n",
    "    # If we receive data, iterate through each artist in turn and process it\n",
    "    else:\n",
    "        for k, v in tag.json().items():\n",
    "            for k_, v_ in v.items():\n",
    "                for lastfm_artist in v_:\n",
    "                    # Try and process the data for one artist\n",
    "                    try:\n",
    "                        trios.append(process_artist(lastfm_artist))\n",
    "                    # Catch errors resulting from irregular item construction, timeouts, and continue\n",
    "                    except (TypeError, KeyError, ConnectionError) as e:\n",
    "                        pass"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T15:28:18.316794300Z",
     "start_time": "2023-06-05T15:23:29.092272700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Concatenate the artist information and drop any duplicates (by ID)\n",
    "df = (\n",
    "    pd.DataFrame([t for t in trios if t is not None])\n",
    "      .drop_duplicates(subset=['mbid'])\n",
    "      .drop(columns=['image', 'streamable', '@attr'])\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T15:30:35.301366800Z",
     "start_time": "2023-06-05T15:30:35.287365500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Subset data to only include those in Levine/Gioia\n",
    "\n",
    "In order to ensure that the artists we include in the corpus played a non-trivial role in jazz history, we cross-reference the list of artists scraped from LastFM with two reference discographies, defined as:\n",
    "\n",
    "- Gioia, T. (2011). The History of Jazz (2nd ed.). New York: Oxford University Press. (`gioia`)\n",
    "- Levine, M. (2011). The Jazz Theory Book. Sebastopol: Sher Music Company. (`levine`)\n",
    "\n",
    "If an artist can be found in the LastFM scraping dataset AND one of the following discographies AND it passes a final manual check against the inclusion criteria, then they can be included in the corpus."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Define the reader function to load in the required text file\n",
    "reader = lambda f: open(fr'{autils.get_project_root()}\\references\\corpus_construction\\{f}.txt', \"r\").read().splitlines()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T15:30:36.478236900Z",
     "start_time": "2023-06-05T15:30:36.459237700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Load in the reference discographies and list of appropriate artists\n",
    "levine = reader('levine')\n",
    "gioia = reader('gioia')\n",
    "appropriate = reader('appropriate')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T15:30:37.385730300Z",
     "start_time": "2023-06-05T15:30:37.371247500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Subset the dataframe to include artists in one of the two discographies & that are acceptable to the inclusion criteria\n",
    "df_cut = df[(df['name'].isin(levine)) | (df['name'].isin(gioia))]\n",
    "df_cut = df[(df['name'].isin(appropriate))].reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T15:30:37.904977500Z",
     "start_time": "2023-06-05T15:30:37.887979Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get metadata for selected artists from LastFM\n",
    "\n",
    "Once we have our list of acceptable artists, we can then make an additional call to the LastFM database to get some additional information that would have taken too long to gather during our initial scraping. This includes the total number of unique tracks by that artist.\n",
    "\n",
    "We define a 'unique track' as one that does not exceed a given similarity threshold with other tracks performed by that artist (i.e. multiple takes of one track are excluded), and which has received over and above a set threshold of plays. This excludes tracks with incorrect or mispelled filenames added by LastFM users."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# These are the substrings we will remove from our track titles\n",
    "REMOVERS = [\n",
    "    'alternate',\n",
    "    'take',\n",
    "    'original',\n",
    "    'mix',\n",
    "    'live'\n",
    "    'digital',\n",
    "    'remaster',\n",
    "    'remastered',\n",
    "    'instrumental',\n",
    "    'intrumental',\n",
    "    'album',\n",
    "    'version',\n",
    "    'rec',\n",
    "    'bonus',\n",
    "    'track'\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T15:30:39.444725300Z",
     "start_time": "2023-06-05T15:30:39.407726200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def get_unique_tracks(\n",
    "        mbid: str, n_pages: int = 10, track_limit: int = 50, listener_limit: int = 100\n",
    ") -> list:\n",
    "    \"\"\"Returns a list of unique track names for a particular artist\"\"\"\n",
    "    def is_english(s: str) -> bool:\n",
    "        \"\"\"Returns whether a string contains only English/ascii characters\"\"\"\n",
    "        try:\n",
    "            s.encode(encoding='utf-8').decode('ascii')\n",
    "        except UnicodeDecodeError:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    def cleaner(s) -> str:\n",
    "        \"\"\"Runs cleaning procedure on a string\"\"\"\n",
    "        # Remove all punctuation and numerical characters from the string, then convert to uppercase\n",
    "        cleaned = ''.join(\n",
    "            [c for c in s.translate(str.maketrans('', '', string.punctuation)) if not c.isdigit()]\n",
    "        ).strip().upper()\n",
    "        # Remove all requested words from the cleaned string and return\n",
    "        for word in REMOVERS:\n",
    "            cleaned = cleaned.replace(word.upper(), '')\n",
    "        return cleaned\n",
    "\n",
    "    seen = []\n",
    "    non_fmt = []\n",
    "    # Iterate through each page of tracks\n",
    "    for page_num in range(n_pages):\n",
    "        # Make the API request\n",
    "        try:\n",
    "            tracks =requests.get(\n",
    "                f\"{ROOT}/?method=artist.gettoptracks&mbid={mbid}&api_key={LASTFM_API_KEY}&format=json&limit={track_limit}&page={page_num}\"\n",
    "            ).json()\n",
    "        # If we time out, log and then continue to the next page\n",
    "        except ConnectionError as e_:\n",
    "            print(e_)\n",
    "            continue\n",
    "        # Otherwise, try and process the page\n",
    "        else:\n",
    "            # Iterate through all the tracks on the page\n",
    "            for track_num in range(track_limit):\n",
    "                # Try and get the name of the track\n",
    "                try:\n",
    "                    match = tracks[\"toptracks\"][\"track\"][track_num]\n",
    "                # Break if the page ends early\n",
    "                except IndexError:\n",
    "                    break\n",
    "                else:\n",
    "                    # If the track has enough listeners\n",
    "                    if int(match[\"listeners\"]) >= listener_limit:\n",
    "                        # Clean the track name to remove punctuations, numbers, etc\n",
    "                        name = cleaner(match['name'])\n",
    "                        # If the track is english and has letters in it\n",
    "                        if len(name) != 0 and is_english(name):\n",
    "                            # Get the similarity of the current track to the previously seen tracks\n",
    "                            sims = [item[1] / 100 for item in process.extract(match['name'], seen)]\n",
    "                            # If the maximum similarity to our seen track names is below the threshold, it's unique\n",
    "                            if len(sims) == 0 or max(sims) < NAME_SIMILARITY_THRESH:\n",
    "                                seen.append(name)\n",
    "                                non_fmt.append(match['name'])\n",
    "    return non_fmt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T15:30:40.352705900Z",
     "start_time": "2023-06-05T15:30:40.342709Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/34 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "465baa0a6a3349ceb99255800e48e106"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique_tracks = []\n",
    "for i, v in tqdm(df_cut.iterrows(), total=df_cut.shape[0]):\n",
    "    unique_tracks.append({\n",
    "        'name': v['name'],\n",
    "        'n_unique_tracks': len(get_unique_tracks(v['mbid'])),\n",
    "        'unique_tracks': get_unique_tracks(v['mbid'])\n",
    "    })"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T15:33:26.342115800Z",
     "start_time": "2023-06-05T15:30:41.860415800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1232\n"
     ]
    }
   ],
   "source": [
    "df_cut['unique_tracks'] = [int(uni['n_unique_tracks']) for uni in unique_tracks]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T16:26:25.729389800Z",
     "start_time": "2023-06-05T16:26:25.708886600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scrape artist metadata from Discogs\n",
    "\n",
    "Once we have our list of artists from LastFM, we can now turn to scraping [Discogs](https://discogs.com) to gain extra metadata from their releases. This will include building up the networks of musicians they played with, which can (in turn) be used to estimate the number of unique combinations of musicians under the banner of a single artist (for example, the Bill Evans Trio contains 4 unique groups of musicians, all led by Bill Evans)\n",
    "\n",
    "This requires us to access the Discogs REST API, the documentation for which is provided [at the following page](https://www.discogs.com/developers). As with LastFM, to access discogs you will need to generate an account and an API key, a tutorial for which is again out of scope for this notebook."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "DISCOGS_API_TOKEN = os.getenv('DISCOGS_API_TOKEN')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T16:35:01.615501300Z",
     "start_time": "2023-06-05T16:35:01.596012400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "headers = {\"Authorization\": f\"Discogs token={DISCOGS_API_TOKEN}\"}\n",
    "params = {\"token\": DISCOGS_API_TOKEN}\n",
    "discogs_endpoint = \"https://api.discogs.com\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T16:35:02.416956200Z",
     "start_time": "2023-06-05T16:35:02.395458600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "def backoff(func):\n",
    "    \"\"\"Simple decorator that forces a one-second wait after an API call to prevent rate limiting\"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        # Discogs API rate-limits authenticated users to 60 API calls per minute\n",
    "        # TODO: implement some sort of error catching here\n",
    "        time.sleep(1)\n",
    "        return func(*args, **kwargs)\n",
    "    return wrapper\n",
    "\n",
    "@backoff\n",
    "def get_discogs_artist_id(artist: str) -> int:\n",
    "    \"\"\"Gets the discogs artist ID for an artist by their name, ripped from LastFM\"\"\"\n",
    "    # Get the artist name by replacing spaces with dashes and converting to lower case\n",
    "    artist = artist.replace(' ', '-').lower()\n",
    "    # The first returned result is (usually) the artist name on Discogs\n",
    "    return requests.get(\n",
    "        f\"{discogs_endpoint}/database/search?q={artist}&type=artist\",\n",
    "        headers=headers,\n",
    "        params=params\n",
    "    ).json()['results'][0]['id']\n",
    "\n",
    "@backoff\n",
    "def get_discogs_artist_releases(discogs_artist_id: int, page_num: int = '') -> dict:\n",
    "    \"\"\"Gets the releases for an artist on discogs by their artist ID\"\"\"\n",
    "    # This forces us to get releases from a particular page\n",
    "    if page_num != '':\n",
    "        page_num = f'&page={page_num}'\n",
    "    # Return the API request\n",
    "    return requests.get(\n",
    "        f\"{discogs_endpoint}/artists/{discogs_artist_id}/releases?sort=year&sort_order=asc&per_page=100{page_num}\",\n",
    "        headers=headers,\n",
    "        params=params\n",
    "    ).json()\n",
    "\n",
    "@backoff\n",
    "def parse_discogs_release_for_artists(discogs_release: str, df_name: str) -> dict:\n",
    "    \"\"\"Parses a single release from Discogs to get the names and roles of the individuals who contributed towards it\"\"\"\n",
    "    # Get the information from a single release\n",
    "    rel = requests.get(\n",
    "        discogs_release['resource_url'],\n",
    "        headers=headers,\n",
    "        params=params\n",
    "    ).json()\n",
    "    # Try to get the names of the contributors to the release\n",
    "    try:\n",
    "        arts = rel['extraartists']\n",
    "    # Break if contributors are not found for this release\n",
    "    except KeyError:\n",
    "        pass\n",
    "    # Otherwise, iterate through all the contributors and return a formatted dictionary\n",
    "    else:\n",
    "        for art in arts:\n",
    "            yield {\n",
    "                'name': df_name,\n",
    "                'release_artist': discogs_release['artist'],\n",
    "                'release_title': rel['title'],\n",
    "                'release_year': rel['year'],\n",
    "                'release_tracks': len(rel['tracklist']),\n",
    "                'artist_name': art['name'],\n",
    "                'artist_role': art['role']\n",
    "            }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-05T16:57:57.090811100Z",
     "start_time": "2023-06-05T16:57:57.082292700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "Total artists:   0%|          | 0/34 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9c591f792ffd45c6ba453a4395248f83"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Bill Evans Trio, page 1/4:   0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eaadbc1aa38543e9a91447c4e80217af"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Bill Evans Trio, page 2/4:   0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aad2de2e5e1143188f97cc2d09052194"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Bill Evans Trio, page 3/4:   0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2c954000621f4ad0b3524aaec194d823"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Bill Evans Trio, page 4/4:   0%|          | 0/72 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9f8dd093fc754ab99e13091454418d1f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Oscar Peterson Trio, page 1/8:   0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cd5320daa74c40a5a82676a56b1af05f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Oscar Peterson Trio, page 2/8:   0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f513f5b1124147f5befa627440a5ab2c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Oscar Peterson Trio, page 3/8:   0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c2b3e4ef810a46948743dd8d6151d776"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Oscar Peterson Trio, page 4/8:   0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c4675aa70d34ea7aa8e37418fadf3aa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Oscar Peterson Trio, page 5/8:   0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5aacdea1c085467c992a472b8a029aa7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Oscar Peterson Trio, page 6/8:   0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "abdf9c0961bc467f956fd79b5d8d05e2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Oscar Peterson Trio, page 7/8:   0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f5992ef32dcb4c4e9e87798ca54a42ca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Oscar Peterson Trio, page 8/8:   0%|          | 0/96 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ddcc60e49c1846cc94e0ed639a692d5e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Ahmad Jamal Trio, page 1/2:   0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3fdad6b79569449d838e7b65d6988855"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Ahmad Jamal Trio, page 2/2:   0%|          | 0/6 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d18c619efba14fccb1848f5c929090c2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = []\n",
    "# Iterate through each of the artists in our dataframe returned from LastFM\n",
    "for i, v in tqdm(df_cut.iterrows(), total=df_cut.shape[0], desc='Total artists'):\n",
    "    # Get the discogs ID for the artist\n",
    "    artist_id = get_discogs_artist_id(v['name'])\n",
    "    # Get the number of pages of releases for this artist\n",
    "    pages = get_discogs_artist_releases(artist_id)['pagination']['pages']\n",
    "    # Iterate through each page\n",
    "    for page in range(1, pages + 1):\n",
    "        # Get the releases on this page\n",
    "        artist_releases = get_discogs_artist_releases(artist_id, page=page)\n",
    "        # Iterate through the releases on the page and get the contributor names and roles\n",
    "        for release in tqdm(artist_releases['releases'], desc=f'{v[\"name\"]}, page {page}/{pages}'):\n",
    "            res.extend(list(parse_discogs_release_for_artists(release, v['name'])))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-06-05T17:02:15.458681900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Output results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cut.to_csv(fr'{autils.get_project_root()}\\references\\corpus_construction\\lastfm_piano_trio_search.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [
     "## Import dependencies\n"
    ],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
