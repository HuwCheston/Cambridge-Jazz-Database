{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Chronology and age analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import dependencies, set constants etc."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python Projects\\jazz-corpus-analysis\\venv\\lib\\site-packages\\statsmodels\\compat\\pandas.py:65: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import Int64Index as NumericIndex\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold, ParameterSampler\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from src import utils\n",
    "from src.features.features_utils import PhaseCorrection, BeatUpbeatRatio, IOIComplexity, TempoSlope, ProportionalAsynchrony, RollingIOISummaryStats\n",
    "from src.detect.detect_utils import OnsetMaker\n",
    "from src.visualise.random_forest_plots import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# These variables are used for the optimization process\n",
    "SEED = 42\n",
    "N_FOLDS = 5\n",
    "N_JOBS = -1\n",
    "# Number of iterations to use in random sampling\n",
    "N_ITER = 10000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Set the seed in NumPy for consistent results across function calls\n",
    "np.random.seed(SEED)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the filepath for our birth/death dates list\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load in data\n",
    "\n",
    "First, we load in our list of `src.detect.detect_utils.OnsetMaker` classes. These contain the location of detected onsets and beats, as well as additional metadata."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "onsets: list[OnsetMaker] = utils.unserialise_object(fr'{utils.get_project_root()}\\models\\matched_onsets_corpus_chronology')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extract features\n",
    "\n",
    "Now, we can extract our desired feature from each OnsetMaker class."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def get_feature_data(feature_cls, cols, extra_str = '', **cls_kwargs):\n",
    "    \"\"\"Creates a class with given kwargs and returns the desired key-value pairs from its summary dictionary\"\"\"\n",
    "    cls = feature_cls(**cls_kwargs)\n",
    "    return {k + extra_str: v for k, v in cls.summary_dict.items() if k in cols}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def process_track(track: OnsetMaker) -> dict:\n",
    "    \"\"\"Processes a single track, extracting all required features, and returns a dictionary\"\"\"\n",
    "    # Convert the summary dictionary (dictionary of arrays) to a dataframe\n",
    "    summary_dict = pd.DataFrame(track.summary_dict)\n",
    "    # These are the positions of downbeats, i.e. the first beat of a measure\n",
    "    downbeats = track.ons['downbeats_manual']\n",
    "    # The tempo and time signature of the track\n",
    "    tempo = track.tempo\n",
    "    time_signature = track.item['time_signature']\n",
    "    # Subset to get my onsets and partner onsets as separate dataframes\n",
    "    for exog_ins in utils.INSTRUMENTS_TO_PERFORMER_ROLES.keys():\n",
    "        my_onsets = track.ons[exog_ins]\n",
    "        my_beats = summary_dict[exog_ins]\n",
    "        their_beats = summary_dict[[i for i in utils.INSTRUMENTS_TO_PERFORMER_ROLES.keys() if i != exog_ins]]\n",
    "        # BEAT-UPBEAT RATIO\n",
    "        bur = get_feature_data(\n",
    "            BeatUpbeatRatio, ['bur_log_mean', 'bur_log_std', 'bur_log_count_nonzero'],\n",
    "            my_onsets=my_onsets, my_beats=my_beats, clean_outliers=True\n",
    "        )\n",
    "        # PHASE CORRECTION\n",
    "        pc = get_feature_data(\n",
    "            PhaseCorrection, ['self_coupling', 'coupling_bass', 'coupling_drums', 'nobs'],\n",
    "            my_beats=my_beats, their_beats=their_beats, order=1\n",
    "        )\n",
    "        # PHASE CORRECTION - PARTNER\n",
    "        # In comparison to the 'full' phase correction model, we only need to get a few columns here\n",
    "        pcb = get_feature_data(\n",
    "            PhaseCorrection, ['coupling_piano', 'nobs'], extra_str='_bass',\n",
    "            my_beats=summary_dict['bass'], their_beats=summary_dict[['piano', 'drums']], order=1\n",
    "        )\n",
    "        pcd = get_feature_data(\n",
    "            PhaseCorrection, ['coupling_piano', 'nobs'], extra_str='_drums',\n",
    "            my_beats=summary_dict['drums'], their_beats=summary_dict[['piano', 'bass']], order=1\n",
    "        )\n",
    "        # PROPORTIONAL ASYNCHRONY\n",
    "        pa = get_feature_data(\n",
    "            ProportionalAsynchrony, ['piano_prop_async_count_nonzero', 'piano_bass_prop_async_nanmean', 'piano_drums_prop_async_nanmean', 'piano_bass_prop_async_nanstd', 'piano_drums_prop_async_nanstd'],\n",
    "            summary_df=summary_dict, my_instr_name=exog_ins\n",
    "        )\n",
    "        # IOI COMPLEXITY\n",
    "        ioi = get_feature_data(\n",
    "            IOIComplexity, ['lz77_mean', 'lz77_std', 'n_onsets_mean', 'n_onsets_std'],\n",
    "            my_onsets=my_onsets, downbeats=downbeats, tempo=tempo, time_signature=time_signature\n",
    "        )\n",
    "        # TEMPO SLOPE\n",
    "        ts = get_feature_data(\n",
    "            TempoSlope, ['tempo_slope', 'tempo_drift'],\n",
    "            my_beats=pd.concat([my_beats, their_beats], axis=1).mean(axis=1)\n",
    "        )\n",
    "        # TEMPO STABILITY\n",
    "        tstab = get_feature_data(\n",
    "            RollingIOISummaryStats, ['rolling_std_count_nonzero', 'rolling_std_median'],\n",
    "            my_onsets=my_beats, downbeats=downbeats, bar_period=4\n",
    "        )\n",
    "        # Return a single dictionary that combines the summary dictionary for all the features\n",
    "        return dict(**track.item, **bur, **pc, **pcb, **pcd, **pa, **ioi, **ts, **tstab, tempo=tempo)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we extract features from all tracks in parallel (should take < 5 minutes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:   48.5s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  2.7min finished\n"
     ]
    }
   ],
   "source": [
    "with Parallel(n_jobs=-1, verbose=5) as parallel:\n",
    "    res = parallel(delayed(process_track)(t) for t in onsets)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}