{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da379e4c-808c-4b87-899f-b4f698036357",
   "metadata": {},
   "source": [
    "# Checking bass onsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "988b49dd-eea5-4968-b3b7-b66180d0e5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from src import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82706922-8f4f-40b5-9d0c-b3ef7a6f609d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corp = utils.load_corpus_from_files(f'{utils.get_project_root()}/data/cambridge-jazz-trio-database-v02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e974a0c2-dda1-40e4-a8e9-92b9dd17035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_between(arr, i1, i2) -> np.array:\n",
    "    \"\"\"From an array `arr`, get all onsets between an upper and lower bound `i1` and `i2` respectively\"\"\"\n",
    "    return arr[np.where(np.logical_and(arr >= i1, arr <= i2))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21d0edf-227e-4063-8d63-2e7dbdde34e7",
   "metadata": {},
   "source": [
    "## Check 'rakes'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d50c1c6-8e46-4576-a5b3-8a6cfcb4258b",
   "metadata": {},
   "source": [
    "We define a 'rake' as three eighth note triplets preceded and followed by a quarter note: see the '3-note rake' on the below image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980d13e0-db63-40ed-8274-ef18fd302c73",
   "metadata": {},
   "source": [
    "![bass rake](https://study.com/cimages/multimages/16/walking_bass_example.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3d7883e-92bf-4f3d-90c2-b57235bdf9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_rake(onsets, b1, b2, b3):\n",
    "    # Get onsets between first and second beat\n",
    "    between = get_between(onsets, b1, b3)\n",
    "    # If we have enough onsets for a three beat rake\n",
    "    if len(between) == 5:\n",
    "        between.sort()\n",
    "        # If beat 1 = onset 1, beat 2 = onset 4\n",
    "        if all((between[0] == b1, between[1] == b2, between[-1] == b3)):\n",
    "            # We probably have a rake\n",
    "            return between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86e3cbfd-91cd-4864-96e7-ae5a3e2d145a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9073807168875347 0.08081973789470916 57\n"
     ]
    }
   ],
   "source": [
    "fs = []\n",
    "total_rakes = 0\n",
    "for track in corp:\n",
    "    if not track.item['has_annotations']:\n",
    "        continue\n",
    "\n",
    "    # PROCESS AUTOMATIC DETECTIONS\n",
    "    # Get both the automatic bass beats and onsets\n",
    "    my_beats = track.summary_dict['bass']\n",
    "    my_onsets = track.ons['bass']\n",
    "    # Process automatically detect beats and onsets\n",
    "    my_rakes = [process_rake(my_onsets, b1, b2, b3) for b1, b2, b3 in zip(my_beats, my_beats[1:], my_beats[2:])]\n",
    "    # Sort the onsets in each rake\n",
    "    my_rakes = [sorted(r) for r in my_rakes if r is not None]\n",
    "    # PROCESS MANUAL DETECTIONS\n",
    "    # Load in the manually detcted bass onsets\n",
    "    my_onsets_man = np.loadtxt(f'{utils.get_project_root()}/references/manual_annotation/{track.item[\"fname\"]}_bass.txt', ndmin=1, usecols=0)\n",
    "    # Get all onsets between the first and last note of each identified rake (with some tolerance)\n",
    "    my_rakes_man = [get_between(my_onsets_man, rake[0] - 0.05, rake[-1] + 0.05) for rake in my_rakes]\n",
    "    # If we don't have any rakes, skip the track\n",
    "    if not all((len(my_rakes) > 0, len(my_rakes_man) > 0)):\n",
    "        continue\n",
    "    # Get the number of rakes identified\n",
    "    total_rakes += len(my_rakes)\n",
    "    # Join together both arrays\n",
    "    ref = np.unique(np.concatenate(my_rakes_man))\n",
    "    onsets = np.unique(np.concatenate(my_rakes))\n",
    "    # Generate the summary dict and append the results\n",
    "    res = track.compare_onset_detection_accuracy(ref=ref, onsets=onsets, window=0.05)\n",
    "    fs.append(res['f_score'])\n",
    "print(np.mean(fs), np.std(fs), total_rakes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0efeed-64c5-4005-97f7-6e0e836c3da5",
   "metadata": {},
   "source": [
    "## Check beats with both bass and drums playing together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9176ac9-ef72-45db-ba1f-58bcac99dbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.924927705501795 0.06104743970455487 10538\n"
     ]
    }
   ],
   "source": [
    "bdres = []\n",
    "nbeats = 0\n",
    "for track in corp:\n",
    "    if not track.item['has_annotations']:\n",
    "        continue\n",
    "\n",
    "    # PROCESS AUTOMATIC DETECTIONS\n",
    "    # Get automatic detected bass beats when both bass and drums playing on same beat\n",
    "    beats_auto = (\n",
    "        pd.DataFrame((track.summary_dict['bass'], track.summary_dict['drums']))\n",
    "        .transpose()\n",
    "        .rename(columns={0: 'bass', 1: 'drums'})\n",
    "        .dropna()\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    my_beats_auto = beats_auto['bass'].values\n",
    "    nbeats += len(my_beats_auto)\n",
    "\n",
    "    # PROCESS MANUAL DETECTIONS\n",
    "    # Load in manually detected bass and drums onsets\n",
    "    bass_onsets_man = np.loadtxt(f'{utils.get_project_root()}/references/manual_annotation/{track.item[\"fname\"]}_bass.txt', ndmin=1, usecols=0)\n",
    "    drums_onsets_man = np.loadtxt(f'{utils.get_project_root()}/references/manual_annotation/{track.item[\"fname\"]}_drums.txt', ndmin=1, usecols=0)\n",
    "    # Match bass and drums onsets to auto detected beats\n",
    "    bass_matched = track.match_onsets_and_beats(track.summary_dict['beats'], bass_onsets_man)\n",
    "    drums_matched = track.match_onsets_and_beats(track.summary_dict['beats'], drums_onsets_man)\n",
    "    # Create the dataframe\n",
    "    beats_man = (\n",
    "        pd.DataFrame((bass_matched, drums_matched))\n",
    "        .transpose()\n",
    "        .rename(columns={0: 'bass', 1: 'drums'})\n",
    "        .dropna()\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    my_beats_man = beats_man['bass'].values\n",
    "\n",
    "    # COMPARE AUTOMATIC AND MANUAL DETECTIONS\n",
    "    res = track.compare_onset_detection_accuracy(ref=my_beats_man, onsets=my_beats_auto, window=0.05)\n",
    "    bdres.append(res['f_score'])\n",
    "print(np.mean(bdres), np.std(bdres), nbeats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c95be15-d4e4-4fc7-aa62-dae6ea8e6211",
   "metadata": {},
   "source": [
    "## Checking specific beats of the bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bae0181e-6fc7-4d10-ac61-4198dedc669b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.9390512485693824 0.06964151206426002\n",
      "2 0.9360016788751553 0.11514022287159142\n",
      "3 0.9469217641316713 0.060315214214627294\n",
      "4 0.9502508879139175 0.044844926198127806\n"
     ]
    }
   ],
   "source": [
    "fsbeat = {i: [] for i in range(1, 5)}\n",
    "for track in corp:\n",
    "    if not track.item['has_annotations']:\n",
    "        continue\n",
    "\n",
    "    # Get automatically detected metre\n",
    "    bass_metre_auto = np.column_stack((track.ons['metre_auto'], track.summary_dict['bass']))\n",
    "    # Get manually detected metre\n",
    "    bass_onsets_man = np.loadtxt(f'{utils.get_project_root()}/references/manual_annotation/{track.item[\"fname\"]}_bass.txt', ndmin=1, usecols=0)\n",
    "    bass_matched = track.match_onsets_and_beats(track.summary_dict['beats'], bass_onsets_man)\n",
    "    bass_metre_man = np.column_stack((track.ons['metre_auto'], bass_matched))\n",
    "\n",
    "    # Iterate through each beat in our time signature\n",
    "    for i in range(1, track.item['time_signature'] + 1):\n",
    "        metre_autos = bass_metre_auto[bass_metre_auto[:, 0] == i, 1]\n",
    "        metre_mans = bass_metre_man[bass_metre_man[:, 0] == i, 1]\n",
    "        # Remove nan values\n",
    "        metre_autos = metre_autos[~pd.isnull(metre_autos)]\n",
    "        metre_mans = metre_mans[~pd.isnull(metre_mans)]\n",
    "        # Calculate f-score\n",
    "        res = track.compare_onset_detection_accuracy(ref=metre_mans, onsets=metre_autos, window=0.05)\n",
    "        fsbeat[i].append(res['f_score'])\n",
    "for i, vals in fsbeat.items():\n",
    "    print(i, np.mean(vals), np.std(vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a388dcc-2883-405a-9a82-1a8aecb0dafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "piano -0.005539215217091873\n",
      "bass -0.004146696717315414\n",
      "drums -0.0035208749287690445\n"
     ]
    }
   ],
   "source": [
    "for instr in ['piano', 'bass', 'drums']:\n",
    "    print(instr, np.mean([i.item['validation'][instr]['mean_asynchrony'] for i in corp if i.item['validation'][instr] is not None]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
