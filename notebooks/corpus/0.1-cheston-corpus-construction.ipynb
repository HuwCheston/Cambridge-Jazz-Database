{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Building a Representative Corpus of Jazz Piano Trio Recordings\n",
    "\n",
    "Procedure:\n",
    "1. Authenticate with both LastFM and Musicbrainz APIs;\n",
    "2. Scrape LastFM to get a list of the most popular jazz artists with 'trio' in their name;\n",
    "3. Cross-reference the artists scraped from LastFM with two reference jazz discographies, removing those who don't feature in either;\n",
    "4. Scrape Musicbrainz using the artist names and gather information on each of their releases;\n",
    "5. Using the release information, group find the number of tracks recorded by all combinations of musicians that recorded under each act name;\n",
    "6. Find the top 30 combinations of musicians who recorded the greatest number of tracks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import dependencies, set constants etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T10:27:36.637853500Z",
     "start_time": "2023-07-25T10:27:15.570856600Z"
    },
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dotenv\n",
    "import requests\n",
    "import hashlib\n",
    "import os\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import musicbrainzngs\n",
    "import warnings\n",
    "from ast import literal_eval\n",
    "from builtins import any as b_any\n",
    "from datetime import timedelta, datetime\n",
    "from dateutil.parser import parse, ParserError\n",
    "from tqdm.notebook import tqdm\n",
    "from requests.exceptions import ConnectionError\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "from src import utils\n",
    "from src.visualise.corpus_plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T10:27:36.646851800Z",
     "start_time": "2023-07-25T10:27:36.640355300Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# These options just make the outputs from each cell look cleaner\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.options.mode.chained_assignment = None\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T10:27:36.701854600Z",
     "start_time": "2023-07-25T10:27:36.651853900Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# These variables are constants and can be changed if needed\n",
    "N_PAGES = 500  # The number of LastFM pages to scrape artist information from\n",
    "N_ARTISTS = 500  # The number of artists per LastFM page\n",
    "LASTFM_ENDPOINT = \"https://ws.audioscrobbler.com/2.0\"  # This is the LastFM API root directory that we will make our calls to\n",
    "GENRE = 'jazz'  # The LastFM genre to scrape for artist names\n",
    "SEARCH_TAG = 'trio'  # Only consider artists that have this tag in their name\n",
    "USABLE_TRACKS_WORST_CASE = 1/4    # In the worst case, we assume that only this percentage of total tracks will be usable in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T10:27:36.703854400Z",
     "start_time": "2023-07-25T10:27:36.663857600Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define the reader function to load in the required text file\n",
    "reader = lambda f: open(fr'{utils.get_project_root()}\\references\\corpus_construction\\{f}.txt', \"r\").read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Authenticate APIs\n",
    "\n",
    "To access the LastFM API, we need an API key, which must be applied for manually. The procedure for doing so is out of scope for this notebook. Follow the advice given in the [LastFM API documentation](https://www.last.fm/api/authentication): you will first need to register for a user account before you can apply for an API key.\n",
    "\n",
    "Once you have an API key, this should be stored as an environment variables within a file called `.env` that is saved in the root directory of this project folder. Define the LastFM key as `LASTFM_API_KEY`. This will then be loaded in automatically using the `dotenv` package within the following few lines.\n",
    "\n",
    "Musicbrainz does not currently require authentication, beyond setting a user agent. You should store a contact email in `.env`, under the `CONTACT_EMAIL` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T10:27:36.753351800Z",
     "start_time": "2023-07-25T10:27:36.674855400Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load in the environment variables we require for authentication\n",
    "dotenv.load_dotenv(rf\"{utils.get_project_root()}\\.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T10:27:36.753852400Z",
     "start_time": "2023-07-25T10:27:36.691851700Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load in our LastFM API key from .env\n",
    "LASTFM_API_KEY = os.getenv('LASTFM_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T10:27:36.754351900Z",
     "start_time": "2023-07-25T10:27:36.699855500Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This is all the authentication required for Musicbrainz\n",
    "CONTACT_EMAIL = os.getenv('CONTACT_EMAIL')\n",
    "LISTENBRAINZ_URL = 'https://listenbrainz.org/player/?recording_mbids='\n",
    "musicbrainzngs.set_useragent('Jazz-Corpus-Analysis', 1, CONTACT_EMAIL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T10:27:36.999358200Z",
     "start_time": "2023-07-25T10:27:36.712355100Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# These authentication variables aren't currently used, but are created now in case we do end up using them later\n",
    "LASTFM_SHARED_SECRET = os.getenv('LASTFM_SHARED_SECRET')\n",
    "LASTFM_TOKEN = eval(\n",
    "    requests.get(f\"{LASTFM_ENDPOINT}/?method=auth.gettoken&api_key={LASTFM_API_KEY}&format=json\").text\n",
    ")['token']\n",
    "LASTFM_API_SIGNATURE = hashlib.md5(\n",
    "    f\"api_key{LASTFM_API_KEY}methodauth.getSessiontoken{LASTFM_TOKEN}{LASTFM_SHARED_SECRET}\".encode('utf-8')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Scrape artist data from LastFM using API\n",
    "\n",
    "The following cells scrape data from the LastFM API using the information and keys created in the cells above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_total_streams(mbid: str) -> dict:\n",
    "    \"\"\"Gets the total number of streams for an artist by their ID, across all tracks and albums\"\"\"\n",
    "    # Make the API request\n",
    "    request = requests.get(\n",
    "        f\"{LASTFM_ENDPOINT}/?method=artist.getinfo&mbid={mbid}&api_key={LASTFM_API_KEY}&format=json\"\n",
    "    ).json()\n",
    "    # Get the required variable from the request JSON object\n",
    "    return {'playcount': request['artist']['stats']['playcount']}\n",
    "\n",
    "\n",
    "def get_top_n_track_streams(mbid: str, num_tracks: int = 3) -> dict:\n",
    "    \"\"\"Gets the number of streams for the top n tracks by an artist, by their ID\"\"\"\n",
    "    # Make the API request\n",
    "    request = requests.get(\n",
    "        f\"{LASTFM_ENDPOINT}/?method=artist.gettoptracks&mbid={mbid}&api_key={LASTFM_API_KEY}&format=json\"\n",
    "    ).json()\n",
    "    res_ = {}\n",
    "    # Iterate through the required number of tracks\n",
    "    for tr in range(num_tracks):\n",
    "        # Get the name and play count from the given track\n",
    "        res_[f'track_{tr + 1}_name'] = request['toptracks']['track'][tr]['name']\n",
    "        res_[f'track_{tr + 1}_plays'] = request['toptracks']['track'][tr]['playcount']\n",
    "    return res_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def process_artist(artist_: dict) -> dict:\n",
    "    \"\"\"Central function for processing data from a single artist scraped from LastFM\"\"\"\n",
    "    if SEARCH_TAG.upper() in str(artist_['name']).upper():\n",
    "        # We make everything upper case to address any case-sensitivity issues\n",
    "        return {\n",
    "            **artist_,\n",
    "            **get_total_streams(mbid=artist_['mbid']),\n",
    "            **get_top_n_track_streams(mbid=artist_['mbid']),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Empty list to hold our processed data\n",
    "trios = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Iterate through each page of artists on LastFM\n",
    "for i in tqdm(range(1, N_PAGES)):\n",
    "    # Make the API request\n",
    "    try:\n",
    "        tag = requests.get(\n",
    "            f\"{LASTFM_ENDPOINT}/?method=tag.gettopartists&tag={GENRE}&api_key={LASTFM_API_KEY}&page={i}&perpage={N_ARTISTS}&format=json\"\n",
    "        )\n",
    "    # If we time out, log and then continue to the next page\n",
    "    except ConnectionError as e:\n",
    "        print(e)\n",
    "        pass\n",
    "    # If we receive data, iterate through each artist in turn and process it\n",
    "    else:\n",
    "        for k, v in tag.json().items():\n",
    "            for k_, v_ in v.items():\n",
    "                for lastfm_artist in v_:\n",
    "                    # Try and process the data for one artist\n",
    "                    try:\n",
    "                        trios.append(process_artist(lastfm_artist))\n",
    "                    # Catch errors resulting from irregular item construction, timeouts, and continue\n",
    "                    except (TypeError, KeyError, ConnectionError) as e:\n",
    "                        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Concatenate the artist information and drop any duplicates (by ID)\n",
    "df = (\n",
    "    pd.DataFrame([t for t in trios if t is not None])\n",
    "    .drop_duplicates(subset=['mbid'])\n",
    "    .drop(columns=['image', 'streamable', '@attr'])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "for col in ['track_1_plays', 'track_2_plays', 'track_3_plays']:\n",
    "    df[col] = df[col].astype(int)\n",
    "df['combined_plays'] = df['track_1_plays'] + df['track_2_plays'] + df['track_3_plays']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.to_csv(fr'{utils.get_project_root()}\\references\\corpus_construction\\lastfm_piano_trio_search_raw.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv(fr'{utils.get_project_root()}\\references\\corpus_construction\\lastfm_piano_trio_search_raw.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "BarPlotLastFMStreams(df).create_plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Subset data to only include artists in reference discographies\n",
    "\n",
    "In order to ensure that the artists we include in the corpus played a non-trivial role in jazz history, we cross-reference the list of artists scraped from LastFM with two reference discographies, defined as:\n",
    "\n",
    "- Gioia, T. (2011). The History of Jazz (2nd ed.). New York: Oxford University Press. (`gioia`)\n",
    "- Levine, M. (2011). The Jazz Theory Book. Sebastopol: Sher Music Company. (`levine`)\n",
    "\n",
    "If an artist can be found in the dataset scraped from LastFM AND one of the following discographies AND it passes a final manual check against the inclusion criteria, then they can be included in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load in the reference discographies and list of appropriate artists\n",
    "levine = reader('levine')\n",
    "gioia = reader('gioia')\n",
    "appropriate = reader('appropriate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Subset the dataframe to include artists in one of the two discographies & that are acceptable to the inclusion criteria\n",
    "df_cut = df[(df['name'].isin(levine)) | (df['name'].isin(gioia))]\n",
    "df_cut = df[(df['name'].isin(appropriate))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_cut.to_csv(fr'{utils.get_project_root()}\\references\\corpus_construction\\lastfm_piano_trio_search.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    df_cut\n",
    "except NameError:\n",
    "    df_cut = pd.read_csv(fr'{utils.get_project_root()}\\references\\corpus_construction\\lastfm_piano_trio_search.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cut"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Scrape release metadata from Musicbrainz\n",
    "\n",
    "Once we have our list of artists from LastFM, we can now turn to scraping [Musicbrainz](https://musicbrainz.org/) to gather information on their individual releases. This will enable us to understand how many trio releases individual bandleaders made, and how many tracks were on each of these releases. This will also allow us to scrape information about the individual performers on each record, which can then be used to estimate the different networks of musicians that formed part of a named 'trio' over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_mbz_artist_id(artist_str):\n",
    "    \"\"\"Searches Musicbrainz using an artist's name and returns the ID with the closest match\"\"\"\n",
    "    return musicbrainzngs.search_artists(artist=artist_str)['artist-list'][0]['id']\n",
    "\n",
    "def get_mbz_artist_release_groups(\n",
    "        artist_id_,\n",
    "        release_types: tuple = ('album', 'live'),\n",
    "        limit: int = 100,\n",
    "):\n",
    "    \"\"\"Returns all release groups associated with a particular artist, by their musicbrainz ID.\n",
    "\n",
    "    A release group is, essentially, a 'master' recording that may have been printed and pressed under\n",
    "    multiple different titles, in different formats, and in different countries over the years.\n",
    "    \"\"\"\n",
    "    for release_type in release_types:\n",
    "        # This gets the item offset\n",
    "        offset = int(np.floor(musicbrainzngs.browse_release_groups(\n",
    "            artist=artist_id_,\n",
    "            release_type=release_type,\n",
    "            limit=1,\n",
    "        )['release-group-count'] / 100))\n",
    "        for off in range(offset + 1):\n",
    "            yield from musicbrainzngs.browse_release_groups(\n",
    "                artist=artist_id_,\n",
    "                release_type=release_type,\n",
    "                limit=limit,\n",
    "                includes=['artist-credits'],\n",
    "                offset=off\n",
    "            )['release-group-list']\n",
    "\n",
    "\n",
    "def get_earliest_mbz_release_from_release_group(\n",
    "        release_grp_: dict,\n",
    "        release_status: tuple = 'official',\n",
    "        limit: int = 100,\n",
    ") -> dict | None:\n",
    "    \"\"\"Get the information relating to the first release of a record from a release group\"\"\"\n",
    "\n",
    "    # Browse musicbrainz to get all releases under this release group\n",
    "    releases_ = musicbrainzngs.browse_releases(\n",
    "        release_group=release_grp_['id'],\n",
    "        release_status=release_status,\n",
    "        limit=limit,    # We don't use offsets here, we won't have more than 100 unique releases of one record\n",
    "    )['release-list']\n",
    "    # Empty lists to store our release data and ID variables\n",
    "    dates = []\n",
    "    ids = []\n",
    "    # Iterate through all the releases of this record\n",
    "    for rel in releases_:\n",
    "        # Try and parse the date to a machine-readable format, and keep the ID too\n",
    "        try:\n",
    "            dates.append(parse(rel['date'], fuzzy=True))\n",
    "        # If we don't have a date for this release, continue to the next one\n",
    "        except KeyError:\n",
    "            continue\n",
    "        # Keep the IDs of any releases where we also have dates\n",
    "        else:\n",
    "            ids.append(rel['id'])\n",
    "    # Return the release whose ID matches the ID of the chronologically-earliest release\n",
    "    try:\n",
    "        return [rel for rel in releases_ if rel['id'] == ids[np.argmin(dates)]][0]\n",
    "    # If none of the releases have dates associated with them, try and return the first release in the list\n",
    "    except (ValueError, IndexError):\n",
    "        try:\n",
    "            return releases_[0]\n",
    "        # If we have an error here, it's because we don't have any releases in the first place, so return None\n",
    "        except IndexError:\n",
    "            return None\n",
    "\n",
    "\n",
    "def getter(collection: str, attribute: str, nest: str = None, fallback=''):\n",
    "    \"\"\"Simple wrapper function for attempting to get an item from a dictionary\"\"\"\n",
    "    try:\n",
    "        # If we've passed a nest level in, subset our collection by this level\n",
    "        if nest is not None:\n",
    "            collection = collection[nest]\n",
    "        return collection[attribute]\n",
    "    # If we don't have our attribute in the dictionary, return our fallback (empty string)\n",
    "    except KeyError:\n",
    "        return fallback\n",
    "\n",
    "\n",
    "def get_work_info(track):\n",
    "    try:\n",
    "        work_list = track['recording']['work-relation-list']\n",
    "    except KeyError:\n",
    "        return {}\n",
    "    else:\n",
    "        for work in work_list:\n",
    "            yield {\n",
    "                'work_begin': getter(work, 'begin'),\n",
    "                'work_end': getter(work, 'end'),\n",
    "                'work_title': getter(work, 'title', nest='work'),\n",
    "                'work_type': getter(work, 'type'),\n",
    "            }\n",
    "\n",
    "\n",
    "def get_release_info(rel):\n",
    "    return {\n",
    "        'release_title': getter(rel, 'title', nest='release'),\n",
    "        'release_status': getter(rel, 'status', nest='release'),\n",
    "        'release_quality': getter(rel, 'quality', nest='release'),\n",
    "        'release_id': getter(rel, 'id', nest='release'),\n",
    "        'release_packaging': getter(rel, 'packaging', nest='release'),\n",
    "        'release_date': getter(rel, 'date', nest='release'),\n",
    "        'release_country': getter(rel, 'country', nest='release'),\n",
    "    }\n",
    "\n",
    "def get_artist_info(track):\n",
    "    try:\n",
    "        artist_list = track['recording']['artist-relation-list']\n",
    "    except KeyError:\n",
    "        return {}\n",
    "    else:\n",
    "        for artist_ in artist_list:\n",
    "            yield {\n",
    "                'artist_id': getter(artist_, 'id', nest='artist'),\n",
    "                'artist_role': getter(artist_, 'attribute-list'),\n",
    "                'artist_name': getter(artist_, 'name', nest='artist'),\n",
    "                'artist_type': getter(artist_, 'type'),\n",
    "                'artist_begin': getter(artist_, 'begin'),\n",
    "                'artist_end': getter(artist_, 'end'),\n",
    "                'artist_details': getter(artist_, 'disambiguation', nest='artist'),\n",
    "            }\n",
    "\n",
    "def get_release_artist(track):\n",
    "    try:\n",
    "        return [getter(a['artist'], 'name') for a in track['recording']['artist-credit'] if isinstance(a, dict)]\n",
    "    except (KeyError, TypeError):\n",
    "        return ''\n",
    "\n",
    "\n",
    "def get_recording_info(track):\n",
    "    return {\n",
    "        'recording_position': getter(track, 'position'),\n",
    "        'recording_number': getter(track, 'number'),\n",
    "        'recording_length': getter(track, 'length'),\n",
    "        'recording_id_for_lbz': getter(track, 'id', nest='recording'),\n",
    "        'recording_title': getter(track, 'title', nest='recording'),\n",
    "        'track_id_maybe_not_needed': getter(track, 'id')\n",
    "    }\n",
    "\n",
    "\n",
    "def parse_mbz_release_info(release: dict, searched_artist_name: str) -> dict:\n",
    "    \"\"\"Parses artist and contributor info from a musicbrainz release\"\"\"\n",
    "    # Get the release by our ID and include the values we need\n",
    "    rel = musicbrainzngs.get_release_by_id(\n",
    "        id=release['id'],\n",
    "        includes=[\n",
    "            'artist-credits',\n",
    "            'labels',\n",
    "            'recordings',\n",
    "            'recording-level-rels',\n",
    "            'work-rels',\n",
    "            'work-level-rels',\n",
    "            'artist-rels'\n",
    "        ],\n",
    "        release_status=['official']\n",
    "    )\n",
    "    release_info = get_release_info(rel)\n",
    "    # Medium list: the list of 'things' in a release, e.g. individual CDs, discs\n",
    "    try:\n",
    "        medium_list = rel['release']['medium-list']\n",
    "    except KeyError:\n",
    "        return\n",
    "    else:\n",
    "        for medium in medium_list:\n",
    "            # Track list: the list of pieces/songs/tracks on a medium\n",
    "            try:\n",
    "                track_list = medium['track-list']\n",
    "            except KeyError:\n",
    "                continue\n",
    "            else:\n",
    "                for track in track_list:\n",
    "                    yield {\n",
    "                        'searched_artist_name': searched_artist_name,\n",
    "                        'release_artist': get_release_artist(track),\n",
    "                        **release_info,\n",
    "                        **get_recording_info(track),\n",
    "                        'artist_list': list(get_artist_info(track)),\n",
    "                        'work_list': list(get_work_info(track)),\n",
    "                    }\n",
    "\n",
    "\n",
    "def get_artist_title_for_writing(name):\n",
    "    \"\"\"Replaces invalid characters in an artist name string so that it can be saved\"\"\"\n",
    "    return name.replace(\" \", \"_\").replace(\"\\\\\", \"_\").replace('/', '_').lower()\n",
    "\n",
    "def write_artist_release_info_to_csv(artist_releases: list, artist_name: str):\n",
    "    \"\"\"Dumps release information from a particular artist to a .csv file\"\"\"\n",
    "    pd.DataFrame(artist_releases).to_csv(fr'{utils.get_project_root()}\\references\\corpus_construction\\musicbrainz_search\\{artist_name}.csv')\n",
    "\n",
    "\n",
    "# Obtain the list of artists that we've already processed\n",
    "preprocessed = os.listdir(fr'{utils.get_project_root()}\\references\\corpus_construction\\musicbrainz_search')\n",
    "# Read in the list of valid artist names from our text file\n",
    "musicbrainz_artists = pd.read_csv(fr'{utils.get_project_root()}\\references\\corpus_construction\\musicbrainz_artists.csv')['artist'].to_list()\n",
    "# Iterate over every artist (with a progress bar)\n",
    "for artist in tqdm(musicbrainz_artists):\n",
    "    # Skip processing the artist if we've already done so in the past\n",
    "    if f\"{get_artist_title_for_writing(artist)}.csv\" in preprocessed:\n",
    "        continue\n",
    "    res = []\n",
    "    # Get the ID of our artist from Musicbrainz\n",
    "    artist_id = get_mbz_artist_id(artist)\n",
    "    # Get all release groups under that artist ID\n",
    "    release_grps = list(get_mbz_artist_release_groups(artist_id))\n",
    "    for release_grp in tqdm(release_grps, desc=f\"{artist}, MBID: {artist_id.upper()}\"):\n",
    "        # Get the earliest release for that release group\n",
    "        earliest_release = get_earliest_mbz_release_from_release_group(release_grp)\n",
    "        if earliest_release is not None:\n",
    "            # Parse artist info from the earliest release\n",
    "            release_info = list(parse_mbz_release_info(earliest_release, artist))\n",
    "            # Extend the list we're creating\n",
    "            res.extend(release_info)\n",
    "    # Once we've scraped all the releases for an artist, we can dump the information to a csv.\n",
    "    write_artist_release_info_to_csv(res, get_artist_title_for_writing(artist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Clean Musicbrainz output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load the musicbrainz search results\n",
    "\n",
    "For every bandleader obtained from the LastFM search, we dumped `.csv` files from scraping Musicbrainz. Now, we'll load these all in as a single `pd.DataFrame` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T15:38:06.690129400Z",
     "start_time": "2023-07-10T15:38:06.111133500Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def process_release_with_multiple_works(work_list):\n",
    "    \"\"\"For recordings associated with multiple works, e.g. medleys, process data to get one result for the recording\"\"\"\n",
    "    works = defaultdict(set)\n",
    "    for d in work_list:\n",
    "        for k, v in d.items():\n",
    "            works[k].add(v)\n",
    "    works = dict(works)\n",
    "    for k, v in works.items():\n",
    "        try:\n",
    "            works[k] = [i for i in works[k] if i != ''][0]\n",
    "        except IndexError:\n",
    "            works[k] = ''\n",
    "    return works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T15:38:39.966125200Z",
     "start_time": "2023-07-10T15:38:06.135129700Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rows = []\n",
    "search_dir = fr\"{utils.get_project_root()}\\references\\corpus_construction\\musicbrainz_search\"\n",
    "for file in tqdm(os.listdir(search_dir)):\n",
    "    with open(search_dir + '\\\\' + file, encoding='utf8') as f:\n",
    "        for row in csv.DictReader(f, skipinitialspace=True):\n",
    "            work_list = literal_eval(row['work_list'])\n",
    "            if len(work_list) == 0:\n",
    "                works = {col: '' for col in ['work_begin', 'work_end', 'work_title', 'work_type']}\n",
    "            elif len(work_list) == 1:\n",
    "                works = work_list[0]\n",
    "            elif len(work_list) > 1:\n",
    "                works = process_release_with_multiple_works(work_list)\n",
    "            art_list = literal_eval(row['artist_list'])\n",
    "            row.pop('artist_list', None)\n",
    "            row.pop('work_list', None)\n",
    "            for art in art_list:\n",
    "                rows.append(row | art | works)\n",
    "\n",
    "mbz = pd.DataFrame(rows).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Get the estimated date of recording\n",
    "\n",
    "This is complicated. Musicbrainz gives us four dates we can readily access, relating to when a recording was made. These are called `artist_begin`, `artist_end`, `work_begin`, and `work_end`. In many cases, these will all be the same. In some situations, such as when a recording was made over multiple days, however, we will get a range of dates, corresponding to the first and last date of recording. What we can do here is interpolate between the 25th and 75th quantile date in these range, to estimate the day of recording.\n",
    "\n",
    "We use quantiles, rather than first/last date, to account for issues where a date may have been entered incorrectly (e.g. [`Return to Forever`](https://musicbrainz.org/recording/64a92f98-fd34-4346-8a31-295858b3dbb6), Stanley Clarke's `artist_begin` is `1772`, rather than `1972` as it is for the other performers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T15:39:03.020629200Z",
     "start_time": "2023-07-10T15:38:39.965625400Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# For any release, set missing dates equal to the most frequently observed date for that release\n",
    "mbz_ = mbz.copy(deep=True)\n",
    "for idx, grp in mbz_.groupby('release_id'):\n",
    "    # Get all dates as one list\n",
    "    sub = grp[['artist_begin', 'artist_end', 'work_begin', 'work_end']].melt().drop('variable',axis=1)['value']\n",
    "    # Get non-missing dates\n",
    "    non_zero = sub[sub != '']\n",
    "    # Try and get the most commonly observed date, or use NaN if all dates are missing\n",
    "    mode = np.nan\n",
    "    try:\n",
    "        mode = non_zero.mode().iloc[0]\n",
    "    except IndexError:\n",
    "        mode = np.nan\n",
    "    finally:\n",
    "        # Set missing dates equal to the mode/nan\n",
    "        for col in ['artist_begin', 'artist_end', 'work_begin', 'work_end']:\n",
    "            mbz_.loc[grp[grp[col] == ''][col].index, col] = mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T15:40:08.377129300Z",
     "start_time": "2023-07-10T15:39:03.043129700Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Correct date columns to datetime object\n",
    "def parser(x):\n",
    "    if isinstance(x, float):\n",
    "        x = np.floor(x)\n",
    "    try:\n",
    "        return parse(str(x), fuzzy=True, default=datetime(3000, 1, 1, 0, 0))\n",
    "    except ParserError:\n",
    "        return pd.NaT\n",
    "\n",
    "\n",
    "for col in ['release_date', 'artist_begin', 'artist_end', 'work_begin', 'work_end']:\n",
    "    mbz_[col] = mbz_[col].apply(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T15:40:21.456625300Z",
     "start_time": "2023-07-10T15:40:08.378626500Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# For all of our available dates, interpolate between the 25th and 75th quantile date to estimate the day of recording\n",
    "def interpolate_date(grp) -> datetime:\n",
    "    \"\"\"Interpolate between an array of datetime objects\"\"\"\n",
    "    melt = grp[['artist_begin', 'artist_end', 'work_begin', 'work_end']].melt().drop('variable',axis=1)['value']\n",
    "    begin = melt.quantile(0.25).to_pydatetime()\n",
    "    end = melt.quantile(0.75).to_pydatetime()\n",
    "    try:\n",
    "        diff = timedelta(seconds=(end - begin).total_seconds() / 2)\n",
    "        grp['recording_date_estimate'] = begin + diff\n",
    "    except ValueError:\n",
    "        grp['recording_date_estimate'] = pd.NaT\n",
    "    return grp['recording_date_estimate']\n",
    "\n",
    "\n",
    "mbz_['recording_date_estimate'] = mbz_.groupby('release_id', group_keys=False).apply(interpolate_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Clean artist type and role variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T15:40:21.721627Z",
     "start_time": "2023-07-10T15:40:21.487628200Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Transfer information on performer type to role column\n",
    "for ty in ['vocal', 'performing orchestra', 'samples from artist', 'misc']:\n",
    "    mbz_.loc[mbz_['artist_type'] == ty, 'artist_role'] = f\"['{ty}']\"\n",
    "    mbz_.loc[mbz_['artist_type'] == ty, 'artist_type'] = 'instrument'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T15:40:24.426128900Z",
     "start_time": "2023-07-10T15:40:21.722625700Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the string representation of a list column to an actual Python list, catching invalid rows\n",
    "mbz_['artist_role_'] = mbz_['artist_role'].apply(lambda ro: literal_eval(str(ro)) if str(ro) != '' else '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Drop non-performer contributor types\n",
    "These are mostly producers, mixing engineers, etc. who are credited on releases but did not actually perform on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T15:40:24.964635100Z",
     "start_time": "2023-07-10T15:40:24.429632300Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mbz_ = mbz_[mbz_['artist_type'].isin(['instrument', 'performer'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Drop tracks containing invalid instruments\n",
    "\n",
    "When we scraped Musicbrainz, we collected all recordings made by a particular bandleader: this includes their trio recordings, but also recordings made in any other configuration, such as quartets, quintets, big band, solo recordings, etc. We need to remove these by dropping any tracks where an instrument that is not part of the standard piano-bass-drums lineup was reported to have performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T15:40:24.985131200Z",
     "start_time": "2023-07-10T15:40:24.974130100Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We need at least three artists to be credited as playing these instruments\n",
    "include_instrs = [\n",
    "    'bass', 'drums', 'piano',\n",
    "]\n",
    "# Disqualify a release if it contains these instruments\n",
    "# TODO: can we create this list iteratively?\n",
    "exclude_instrs = [\n",
    "    'French horn', 'woodwind', 'solo', 'reeds', 'membranophone', 'oboe', 'harmonica', 'flugelhorn', 'gumbri', 'piccolo', 'bell', 'harp', 'congas', 'bongos', 'mellophone', 'accordion', 'tabla', 'washtub bass', 'tambourine', 'clavinet', 'additional', 'chamberlin', 'banjo', 'marimba', 'baritone', 'brass', 'saxophone', 'clarinet', 'trombone', 'guitar', 'strings', 'cello', 'viol', 'vibraphone', 'electric', 'flute', 'tuba', 'oon', 'percussion', 'foot stomps', 'bass drum', 'celesta', 'tack', 'keyboard', 'Rhodes', 'timpani', 'duo', 'organ', 'electronic', 'synthesizer', 'vocal', 'executive', 'co', 'recorder', 'vocoder', 'slit drum', 'family', 'performing orchestra', 'samples from artist', 'misc'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T15:40:38.534125600Z",
     "start_time": "2023-07-10T15:40:24.992129Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def check_instrument(row: pd.Series) -> bool:\n",
    "    \"\"\"Returns True if an artist performed a valid instrument and did not perform an invalid instrument\"\"\"\n",
    "    try:\n",
    "        return all([\n",
    "            any([b_any(word.lower() in x.lower() for x in row) for word in include_instrs]),\n",
    "            not any([b_any(word.lower() in x.lower() for x in row) for word in exclude_instrs])\n",
    "        ])\n",
    "    except TypeError:\n",
    "        return False\n",
    "\n",
    "# TODO: we can probably simplify this\n",
    "mbz_['include_release'] = mbz_['artist_role_'].apply(check_instrument)\n",
    "# Drop tracks containing at least one invalid instrument\n",
    "mbz_ = (\n",
    "    mbz_.groupby(['recording_title', 'recording_title', 'recording_id_for_lbz'])\n",
    "        .filter(lambda x: not any(x['include_release'] == False))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T15:40:44.391125700Z",
     "start_time": "2023-07-10T15:40:38.537127600Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Assert that all tracks only contain valid instruments\n",
    "assert all(\n",
    "    [len(grp[grp['include_release'] == False]) == 0 for idx, grp in mbz_.groupby(['recording_title', 'release_title', 'recording_id_for_lbz'])]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Drop duplicates of one recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T15:40:44.503623300Z",
     "start_time": "2023-07-10T15:40:44.397623800Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mbz_ = mbz_.drop_duplicates(subset=['recording_title', 'recording_length', 'release_title', 'recording_id_for_lbz', 'artist_name'], keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Format instrument names\n",
    "\n",
    "The names of instruments returned from Musicbrainz aren't standardized: for example, `piano` may be referred to using `piano`, `grand piano`, `piano (solo)`, among others. We can format these fairly easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T15:40:44.775177Z",
     "start_time": "2023-07-10T15:40:44.489128200Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def format_instrument(row: pd.Series):\n",
    "    checks = [b_any(word in x for x in row) for word in include_instrs]\n",
    "    return ''.join(np.array(include_instrs)[np.where(checks)[0]])\n",
    "\n",
    "mbz_['artist_instrument'] = mbz_['artist_role_'].apply(format_instrument)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Drop recordings containing more than one performer on a single instrument\n",
    "\n",
    "These are recordings where more than one performer played on a single instrument in the trio configuration. These usually have fairly obvious-to-spot titles, for instance `An Evening with Herbie Hancock & Chick Corea` (contains both Herbie & Chick on piano), `Ray Brown's New Two Bass Hits` (contains both Ray Brown and Pierre Boussaguet on double bass). We can remove these by simply dropping any tracks where we have more than one unique credit for a particular trio instrument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T15:40:58.353126100Z",
     "start_time": "2023-07-10T15:40:44.779126900Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mbz_ = (\n",
    "    mbz_.groupby(['recording_title', 'recording_length', 'release_title', 'recording_id_for_lbz',])\n",
    "        .filter(lambda x: not any(len(g) > 1 for _, g in x.groupby('artist_instrument')))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Drop recordings that do not contain a full trio\n",
    "\n",
    "It's quite common on an album to have occasional tracks that may only include a subset of the overall trio -- e.g. piano solos, duets between pianist and bassist. For examples, see both versions of `Epilogue` on `Everybody Digs Bill Evans`, by the `Bill Evans Trio`. We need to remove these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T15:41:01.033126900Z",
     "start_time": "2023-07-10T15:40:58.358126300Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mbz_ = (\n",
    "    mbz_.groupby(['recording_title', 'recording_length', 'release_title', 'recording_id_for_lbz',])\n",
    "        .filter(lambda x: sorted(x['artist_instrument'].unique()) == sorted(include_instrs))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Pivot the dataframe to get the whole ensemble on one row\n",
    "\n",
    "The tracks that are left in the dataframe should contain one pianist, one bassist, and one drummer only. We can now pivot the dataframe to get all of these performers on the same row, making it easier to work with combinations of performers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T15:41:01.196627100Z",
     "start_time": "2023-07-10T15:41:01.040134600Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "piv = mbz_.pivot_table(\n",
    "    index=['searched_artist_name', 'recording_title', 'release_title', 'recording_length', 'recording_id_for_lbz', 'release_artist', 'release_date', 'release_country', 'work_begin', 'work_end', 'recording_position', 'recording_date_estimate'],\n",
    "    columns=['artist_instrument'],\n",
    "    aggfunc='first',\n",
    "    values='artist_name'\n",
    ").reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Drop recordings not made by the leader\n",
    "\n",
    "Occasionally, we can run into issues where the artist we initially searched for is not present on a track. For an example, see the album [`Just One of Those Things`](https://musicbrainz.org/release/b1f218be-3aaf-4b7c-a9ca-fab91c29f82e). We searched for `Bud Powell` to find this release, but some of the tracks on the album are by the `Duke Jordan Trio`, who we did not search for. We need to drop the tracks on this album where `Bud Powell` is not recorded as playing either piano, bass or drums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T15:41:06.596665Z",
     "start_time": "2023-07-10T15:41:01.203630100Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def filter_non_leader_recordings(row: pd.Series):\n",
    "    \"\"\"Filters tracks where the searched for leader does not appear as a performer on a track\"\"\"\n",
    "    # We accomplish the filtering by looking for overlaps of at least two words between the artist name we searched for and one of the artists in the trio.\n",
    "    # This means that cases where we searched for 'The Bill Evans Trio' will pass, provided that Bill Evans can be found on either piano, bass, or drums.\n",
    "    return any(len(set(row['searched_artist_name'].split()) & set(art.split())) >= 2 for art in row[['bass', 'drums', 'piano']].to_list())\n",
    "\n",
    "piv_ = piv[piv.apply(filter_non_leader_recordings, axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Drop incomplete and exceptionally short tracks\n",
    "\n",
    "Occasionally albums contain tracks which are very short. This is especially common on live albums, which may include tracks variously containing words like `Introduction`, `Warm-up`, `Announcement`, etc. These usually don't actually contain any playing, and just consist of the venue MC announcing the name of the artist and the audience applauding them. In other cases, compilation albums may include tracks labelled as `Breakdown`, `False Start`, `Fragment`, etc. These are takes that don't contain a full performance and instead break down, often after only a few bars. We can remove these tracks by first dropping tracks which contain words like `warm-up`', `false start` etc. in their name, and then setting a hard cut-off to drop any track with a duration of less than half a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T15:41:06.672166Z",
     "start_time": "2023-07-10T15:41:06.579633500Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "removers = ['false', 'announ', 'introd', 'warm', 'fragment', 'final', 'break', 'epilogue']\n",
    "for remover in removers:\n",
    "    piv_ = piv_[~piv_['recording_title'].str.lower().str.contains(remover)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T15:41:06.705123500Z",
     "start_time": "2023-07-10T15:41:06.670662Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Drop recordings that do not have track runtimes provided\n",
    "piv_ = piv_[piv_['recording_length'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T15:41:06.775126400Z",
     "start_time": "2023-07-10T15:41:06.684624700Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "piv_['recording_length_'] = piv_['recording_length'].astype(int).apply(lambda x: timedelta(milliseconds=x))\n",
    "piv_ = piv_[piv_['recording_length_'] > timedelta(seconds=30)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Convert performer names to first initial/surname\n",
    "\n",
    "The names for some performers are inconsistently labelled on Musicbrainz; for example, the bassist `Eddie Gomez` is also occasionally labelled as `Edward M. Gomez`. We can account for this by converting all performer names into a common format, this being the first initial of their first name and their surname. So, `Eddie Gomez` and `Edward M. Gomez` would both become `E. Gomez`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T15:41:06.871126400Z",
     "start_time": "2023-07-10T15:41:06.727634800Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def initials(a):\n",
    "    \"\"\"Converts a list of strings of arbitrary length to their first initial\"\"\"\n",
    "    if len(a) == 0:\n",
    "        return ''\n",
    "    return ''.join(map(lambda li: li[0] + '.', [a[0]]))\n",
    "\n",
    "def abbreviate(s):\n",
    "    \"\"\"Abbreviates a name to surname, first initial\"\"\"\n",
    "    l = s.split()\n",
    "    return f'{l[-1]}, {initials(l[0:-1])}'\n",
    "\n",
    "for instr in include_instrs:\n",
    "    piv_[f'{instr}_'] = piv_[instr].apply(abbreviate).apply(lambda s: \"\".join(c for c in s if ord(c) < 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T15:41:06.871627700Z",
     "start_time": "2023-07-10T15:41:06.833127800Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We can also convert track numbers to integers\n",
    "piv_['recording_position'] = piv_['recording_position'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Match artist names with bandleaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T15:41:06.872129400Z",
     "start_time": "2023-07-10T15:41:06.846634100Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bls = pd.read_csv(fr'{utils.get_project_root()}\\references\\corpus_construction\\artist_birth_death.csv')\n",
    "clean = pd.merge(piv_, bls, left_on='searched_artist_name', right_on='artist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T15:41:06.891127900Z",
     "start_time": "2023-07-10T15:41:06.875630Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# For artists who are currently alive, replace their date of death with today\n",
    "now = datetime.now().strftime('%Y-%m-%d')\n",
    "clean['death'] = clean['death'].fillna(now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T15:41:07.654666700Z",
     "start_time": "2023-07-10T15:41:06.886126400Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clean['birth'] = clean['birth'].apply(parser)\n",
    "clean['death'] = clean['death'].apply(parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Drop tracks by the same artist duplicated across several albums\n",
    "\n",
    "Sometimes, as in the case of compilation albums, the same track can be duplicated across multiple releases. While there is no sure-fire way to accomodate all cases where this might have happened without dropping all tracks with duplicate names -- and potentially dropping alternate takes as a result! -- one way is to search group by tracks with the same name and combination of performers, and then drop any which have very similar durations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T15:41:19.013625500Z",
     "start_time": "2023-07-10T15:41:07.637628200Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clean = clean.reset_index(drop=True)\n",
    "for idx, grp in clean.groupby(['bandleader', 'recording_title', 'piano', 'bass', 'drums']):\n",
    "    lead = grp['recording_length_'].sort_values().diff()\n",
    "    if len(lead) > 1:\n",
    "        clean = clean.drop(lead[lead < timedelta(seconds=3)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T15:41:19.029125200Z",
     "start_time": "2023-07-10T15:41:19.016624Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We can also drop duplicates that have the same musicbrainz id\n",
    "clean = clean.drop_duplicates(subset=['bandleader', 'recording_id_for_lbz'], keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Remove tracks recorded after a bandleader's death/before their birth\n",
    "\n",
    "This is usually just due to faulty record keeping on Musicbrainz: e.g. a few tracks on Bill Evans Trio, [Live At The Penthouse Seattle 1966](https://musicbrainz.org/release/f8197342-b35e-4783-b8d8-2bf542cfb51c) are listed as being recorded in 1996, rather than 1966."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T15:41:19.055624500Z",
     "start_time": "2023-07-10T15:41:19.032629800Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clean = clean[(clean['death'] > clean['recording_date_estimate']) & (clean['birth'] < clean['recording_date_estimate'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clean[clean['piano_'] == 'Hicks, J.']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T15:41:19.137127600Z",
     "start_time": "2023-07-10T15:41:19.046129700Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clean['trio'] = clean[['piano_', 'bass_', 'drums_']].agg('/'.join, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save the cleaned dataframe to a .csv to make loading easier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clean.to_csv(fr'{utils.get_project_root()}\\references\\corpus_construction\\mbz_output_cleaned.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clean = pd.read_csv(fr'{utils.get_project_root()}\\references\\corpus_construction\\mbz_output_cleaned.csv', parse_dates=['recording_date_estimate', 'recording_length_'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import src.visualise.visualise_utils as vutils\n",
    "\n",
    "BarPlotBandleaderDuration(clean).create_plot()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get the names of the 10 bandleaders with the most recordings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bandleaders = ['Bill Evans', 'Ahmad Jamal', 'Bud Powell', 'Oscar Peterson', 'Keith Jarrett', 'Tommy Flanagan', 'Junior Mance', 'Kenny Barron', 'John Hicks', 'McCoy Tyner']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clean['recording_length_']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T15:41:19.138125300Z",
     "start_time": "2023-07-10T15:41:19.096125Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "small = clean.groupby('bandleader').agg({'recording_title': 'count', 'recording_length_': 'sum'}).reset_index(drop=False)\n",
    "small['recording_length_'] = small['recording_length_'].dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T15:41:43.796768300Z",
     "start_time": "2023-07-10T15:41:43.732727700Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "include = clean[clean['bandleader'].isin(bandleaders)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Plot bandleaders with most number of tracks, and with longest total length of recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T15:26:35.730518400Z",
     "start_time": "2023-06-22T15:26:34.858519200Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BarPlotBandleaderDuration(clean).create_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Subset included data using anchor points"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_anchorpoint(df, n_tracks = 30):\n",
    "    first = df['recording_date_estimate'].min()\n",
    "    last = df['recording_date_estimate'].max()\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        return [\n",
    "            a.to_pydatetime() for a in pd.date_range(\n",
    "                first, last, n_tracks, normalize=True, inclusive='both'\n",
    "            ).to_list()\n",
    "        ]\n",
    "\n",
    "def get_anchorranges(anchors):\n",
    "    start = []\n",
    "    end = []\n",
    "    for a1, a2, a3 in zip(anchors[:], anchors[1:], anchors[2:]):\n",
    "        start.append(a2 - ((a2 - a1) / 2))\n",
    "        end.append(a2 + ((a3 - a2) / 2))\n",
    "    start.insert(0, anchors[0])\n",
    "    end.insert(0, anchors[0] + (anchors[1] - anchors[0]) / 2)\n",
    "    start.append(anchors[-1] - (anchors[-1] - anchors[-2]) / 2)\n",
    "    end.append(anchors[-1] + timedelta(days=1))\n",
    "    return [(s, a, e) for s, a, e in zip(start, anchors, end)]\n",
    "\n",
    "\n",
    "def subset_df_by_anchor(grp: pd.DataFrame, anc_range: tuple):\n",
    "    cols = [\n",
    "        'anchor_number',\n",
    "        'anchor_point',\n",
    "        'recording_date_estimate',\n",
    "        'days_from_anchor',\n",
    "        'bandleader',\n",
    "        'piano',\n",
    "        'bass',\n",
    "        'drums',\n",
    "        'recording_title',\n",
    "        'recording_position',\n",
    "        'release_title',\n",
    "        'recording_length_',\n",
    "        'recording_id_for_lbz'\n",
    "    ]\n",
    "    for num, (start, anc, end) in enumerate(anc_range, 1):\n",
    "        subset = grp[(grp['recording_date_estimate'] >= start) & (grp['recording_date_estimate'] < end)]\n",
    "        subset['recording_length_'] = subset[\"recording_length_\"].astype(str).str.replace('0 days 00:', '')\n",
    "        subset['recording_id_for_lbz'] = LISTENBRAINZ_URL + subset['recording_id_for_lbz']\n",
    "        subset['anchor_number'] = num\n",
    "        subset['anchor_point'] = anc.strftime('%Y-%m-%d')\n",
    "        subset['days_from_anchor'] = (subset['recording_date_estimate'] - anc).abs().dt.days\n",
    "        yield (\n",
    "            subset[cols]\n",
    "                  .sort_values(['days_from_anchor', 'release_title', 'recording_position'])\n",
    "                  .reset_index(drop=True)\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "include"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Write subsetted data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_dict = {}\n",
    "for idx, grp in include.groupby('bandleader'):\n",
    "    anchors = get_anchorpoint(grp)\n",
    "    anchorranges = get_anchorranges(anchors)\n",
    "    subs = pd.concat(subset_df_by_anchor(grp, anchorranges)).reset_index(drop=True)\n",
    "    assert len(subs) == len(grp)\n",
    "    df_dict[idx] = subs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fp = fr'{utils.get_project_root()}\\references\\corpus_construction\\anchor_search_300_slices_15.xlsx'\n",
    "with pd.ExcelWriter(fp, engine='openpyxl') as writer:\n",
    "    for key, df in df_dict.items():\n",
    "        df.to_excel(writer, sheet_name=f'{key}', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "include.to_csv(fr'{utils.get_project_root()}\\\\references\\corpus_construction\\include_recordings.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Subset data for Bill Evans case study"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "include = pd.read_csv(fr'{utils.get_project_root()}\\\\references\\corpus_construction\\include_recordings.csv', parse_dates=['recording_date_estimate', 'birth', 'death'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evans_fmt(subset):\n",
    "    cols = [\n",
    "        'recording_title',\n",
    "        'release_title',\n",
    "        'recording_date_estimate',\n",
    "        'bass',\n",
    "        'drums',\n",
    "        'recording_position',\n",
    "        'recording_length_',\n",
    "        'recording_id_for_lbz'\n",
    "    ]\n",
    "    subset['recording_length_'] = subset[\"recording_length_\"].astype(str).str.replace('0 days 00:', '')\n",
    "    subset['recording_id_for_lbz'] = LISTENBRAINZ_URL + subset['recording_id_for_lbz']\n",
    "    return subset[cols].sort_values(by=['release_title', 'recording_position'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fp = fr'{utils.get_project_root()}\\references\\corpus_construction\\trio_search_evans.xlsx'\n",
    "include_trios = include[include['bandleader'] == 'Bill Evans'].groupby('trio').agg({'recording_length': 'sum'}).sort_values('recording_length', ascending=False).head(7).reset_index()['trio'].values\n",
    "with pd.ExcelWriter(fp, engine='openpyxl') as writer:\n",
    "    for idx, trio in include[include['trio'].isin(include_trios)].groupby('trio'):\n",
    "        evans_fmt(trio).to_excel(writer, sheet_name=idx.replace('Evans, B./', '').replace('/', '-'), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "include['recording_length_'] = include['recording_length'].astype(int).apply(lambda x: timedelta(milliseconds=x)).dt.total_seconds()\n",
    "include_trios = include[include['bandleader'] == 'Bill Evans'].groupby('trio').agg({'recording_length': 'sum'}).sort_values('recording_length', ascending=False).head(7).reset_index()['trio'].values\n",
    "small = include[include['bandleader'] == 'Bill Evans'].groupby('trio').agg({'recording_length_': 'sum'}).reset_index(drop=False)\n",
    "small['hours'] = small['recording_length_'] / 3600\n",
    "small.sort_values(by='hours', ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Seven trios recorded at least 5.5 hours of material: all the remaining trios recorded less than 2.5 hours. These latter trios were likely recruited for a specific concert or recording date (or to subsitute in for another, more permanent musician), and do not necessarily constitute a working line-up of 'The Bill Evans Trio'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "d = small.sort_values(by='hours', ascending=False)\n",
    "d['trio'] = d['trio'].str.replace('Evans, B./', '')\n",
    "d['include_'] = d['hours'] > 5\n",
    "g = sns.barplot(data=d, x='trio', y='hours', hue='include_', dodge=False)\n",
    "g.set_xticks(g.get_xticks(), g.get_xticklabels(), rotation=45, ha='right')\n",
    "g.set(xlabel='Trio', ylabel='Total hours')\n",
    "g.get_legend().set_title('Include?')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualize the results!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualise recording year"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the corpus to get acceptable tracks\n",
    "corp = pd.DataFrame(utils.CorpusMaker.from_excel('corpus_chronology', keep_all_tracks=False).tracks)\n",
    "tracks_in_corp = corp['mbz_id'].to_list()\n",
    "include['in_corpus'] = include['recording_id_for_lbz'].isin(tracks_in_corp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TimelinePlotBandleaders(include, include_images=False).create_plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "include['duration'] = pd.to_timedelta(include['recording_length_']).dt.total_seconds()\n",
    "\n",
    "BoxPlotRecordingLength(include).create_plot()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "BarPlotCorpusDuration(include, include_images=False).create_plot()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Network visualisation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "G = nx.from_pandas_edgelist(\n",
    "    pd.DataFrame({\n",
    "        'source': pd.concat((include['piano_'], include['piano_'], include['bass_'], include['bass_'], include['drums_'], include['drums_'])),\n",
    "        'target': pd.concat((include['bass_'], include['drums_'], include['piano_'], include['drums_'], include['bass_'], include['piano_']))\n",
    "    }),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "import src.visualise.visualise_utils as vutils\n",
    "import re\n",
    "\n",
    "nt = Network(height=\"750px\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\", filter_menu=True, cdn_resources='remote')\n",
    "nt.repulsion()\n",
    "# populates the nodes and edges data structures\n",
    "nt.from_nx(G)\n",
    "neighbor_map = nt.get_adj_list()\n",
    "\n",
    "\n",
    "def _get_instr(neigh):\n",
    "    res = []\n",
    "    for n in neigh:\n",
    "        if n in include['piano_'].values:\n",
    "            res.append(n + ' (P)')\n",
    "        elif n in include['bass_'].values:\n",
    "            res.append(n + ' (B)')\n",
    "        else:\n",
    "            res.append(n + ' (D)')\n",
    "    return sorted(res)\n",
    "\n",
    "# add neighbor data to node hover data\n",
    "for node in nt.nodes:\n",
    "    if node['label'] in include['piano_'].values:\n",
    "        node['color'] = vutils.RED\n",
    "    elif node['label'] in include['bass_'].values:\n",
    "        node['color'] = vutils.GREEN\n",
    "    else:\n",
    "        node['color'] = vutils.BLUE\n",
    "\n",
    "\n",
    "    node[\"title\"] = \"Recorded with: \\n\" + \"\\n\".join(_get_instr(neighbor_map[node[\"id\"]]))\n",
    "    node[\"value\"] = len(neighbor_map[node[\"id\"]])\n",
    "\n",
    "# nt.show(rf'{utils.get_project_root()}\\reports\\figures\\corpus_plots\\trio_network_visualisation.html', notebook=False)\n",
    "nt.show('trio_network_visualisation.html', notebook=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inc = include[include['in_corpus']]\n",
    "include.groupby('drums_')['bandleader'].nunique().sort_values()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "include.groupby(['bass_', 'drums_'])['bandleader'].count().sort_values()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corp['time_signature'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": [
     "## Import dependencies\n"
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}